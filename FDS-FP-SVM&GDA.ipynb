{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Train/Dev/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has been already splitted into train and test sets, with a ratio of about 70/30%. \n",
    "\n",
    "For our classification task, in order to fine tune the hyperparameters of the model and select the best features from the data, we further split those sets. So, we end up with train, evaluation and test sets of about 60/20/20% of the overall data, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./data/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take 2/5 of the train set for cross validation and test\n",
    "train_set, dev_test_set = train_test_split(dataset, test_size=0.4, random_state=12)\n",
    "\n",
    "# take 1/2 of the test set for cross validation\n",
    "test_set, dev_set = train_test_split(dev_test_set, test_size=0.5, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tBodyAcc-mean()-X</th>\n",
       "      <th>tBodyAcc-mean()-Y</th>\n",
       "      <th>tBodyAcc-mean()-Z</th>\n",
       "      <th>tBodyAcc-std()-X</th>\n",
       "      <th>tBodyAcc-std()-Y</th>\n",
       "      <th>tBodyAcc-std()-Z</th>\n",
       "      <th>tBodyAcc-mad()-X</th>\n",
       "      <th>tBodyAcc-mad()-Y</th>\n",
       "      <th>tBodyAcc-mad()-Z</th>\n",
       "      <th>tBodyAcc-max()-X</th>\n",
       "      <th>...</th>\n",
       "      <th>fBodyBodyGyroJerkMag-kurtosis()</th>\n",
       "      <th>angle(tBodyAccMean,gravity)</th>\n",
       "      <th>angle(tBodyAccJerkMean),gravityMean)</th>\n",
       "      <th>angle(tBodyGyroMean,gravityMean)</th>\n",
       "      <th>angle(tBodyGyroJerkMean,gravityMean)</th>\n",
       "      <th>angle(X,gravityMean)</th>\n",
       "      <th>angle(Y,gravityMean)</th>\n",
       "      <th>angle(Z,gravityMean)</th>\n",
       "      <th>subject</th>\n",
       "      <th>Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6505</th>\n",
       "      <td>0.278909</td>\n",
       "      <td>-0.016122</td>\n",
       "      <td>-0.108804</td>\n",
       "      <td>-0.991421</td>\n",
       "      <td>-0.958884</td>\n",
       "      <td>-0.943642</td>\n",
       "      <td>-0.992854</td>\n",
       "      <td>-0.959690</td>\n",
       "      <td>-0.944281</td>\n",
       "      <td>-0.926421</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.604272</td>\n",
       "      <td>-0.135149</td>\n",
       "      <td>-0.006428</td>\n",
       "      <td>-0.840651</td>\n",
       "      <td>0.548457</td>\n",
       "      <td>-0.690776</td>\n",
       "      <td>0.291574</td>\n",
       "      <td>0.110070</td>\n",
       "      <td>28</td>\n",
       "      <td>SITTING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4384</th>\n",
       "      <td>0.278544</td>\n",
       "      <td>-0.017497</td>\n",
       "      <td>-0.111402</td>\n",
       "      <td>-0.997560</td>\n",
       "      <td>-0.980832</td>\n",
       "      <td>-0.987017</td>\n",
       "      <td>-0.997578</td>\n",
       "      <td>-0.979116</td>\n",
       "      <td>-0.988149</td>\n",
       "      <td>-0.942968</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.919445</td>\n",
       "      <td>-0.089110</td>\n",
       "      <td>-0.044198</td>\n",
       "      <td>-0.607149</td>\n",
       "      <td>0.601884</td>\n",
       "      <td>-0.817034</td>\n",
       "      <td>0.214795</td>\n",
       "      <td>-0.032885</td>\n",
       "      <td>22</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7480</th>\n",
       "      <td>0.243931</td>\n",
       "      <td>-0.004004</td>\n",
       "      <td>-0.122676</td>\n",
       "      <td>-0.092084</td>\n",
       "      <td>0.010789</td>\n",
       "      <td>0.199388</td>\n",
       "      <td>-0.193510</td>\n",
       "      <td>-0.041149</td>\n",
       "      <td>0.186226</td>\n",
       "      <td>0.315973</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.639589</td>\n",
       "      <td>0.368217</td>\n",
       "      <td>0.310372</td>\n",
       "      <td>0.969768</td>\n",
       "      <td>-0.504041</td>\n",
       "      <td>-0.496266</td>\n",
       "      <td>0.268661</td>\n",
       "      <td>0.327231</td>\n",
       "      <td>2</td>\n",
       "      <td>WALKING_DOWNSTAIRS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5960</th>\n",
       "      <td>0.278354</td>\n",
       "      <td>-0.016345</td>\n",
       "      <td>-0.111278</td>\n",
       "      <td>-0.985230</td>\n",
       "      <td>-0.988805</td>\n",
       "      <td>-0.990760</td>\n",
       "      <td>-0.985383</td>\n",
       "      <td>-0.987864</td>\n",
       "      <td>-0.990653</td>\n",
       "      <td>-0.930099</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.950759</td>\n",
       "      <td>0.332895</td>\n",
       "      <td>0.404353</td>\n",
       "      <td>0.222148</td>\n",
       "      <td>0.056738</td>\n",
       "      <td>0.604472</td>\n",
       "      <td>-0.363929</td>\n",
       "      <td>-0.648498</td>\n",
       "      <td>27</td>\n",
       "      <td>LAYING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10196</th>\n",
       "      <td>0.291115</td>\n",
       "      <td>-0.014618</td>\n",
       "      <td>-0.112456</td>\n",
       "      <td>-0.968179</td>\n",
       "      <td>-0.982618</td>\n",
       "      <td>-0.983055</td>\n",
       "      <td>-0.967095</td>\n",
       "      <td>-0.982565</td>\n",
       "      <td>-0.980663</td>\n",
       "      <td>-0.916381</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.940910</td>\n",
       "      <td>-0.090369</td>\n",
       "      <td>0.008545</td>\n",
       "      <td>0.387679</td>\n",
       "      <td>-0.204587</td>\n",
       "      <td>0.449349</td>\n",
       "      <td>-0.501789</td>\n",
       "      <td>-0.490746</td>\n",
       "      <td>24</td>\n",
       "      <td>LAYING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 563 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tBodyAcc-mean()-X  tBodyAcc-mean()-Y  tBodyAcc-mean()-Z  \\\n",
       "6505            0.278909          -0.016122          -0.108804   \n",
       "4384            0.278544          -0.017497          -0.111402   \n",
       "7480            0.243931          -0.004004          -0.122676   \n",
       "5960            0.278354          -0.016345          -0.111278   \n",
       "10196           0.291115          -0.014618          -0.112456   \n",
       "\n",
       "       tBodyAcc-std()-X  tBodyAcc-std()-Y  tBodyAcc-std()-Z  tBodyAcc-mad()-X  \\\n",
       "6505          -0.991421         -0.958884         -0.943642         -0.992854   \n",
       "4384          -0.997560         -0.980832         -0.987017         -0.997578   \n",
       "7480          -0.092084          0.010789          0.199388         -0.193510   \n",
       "5960          -0.985230         -0.988805         -0.990760         -0.985383   \n",
       "10196         -0.968179         -0.982618         -0.983055         -0.967095   \n",
       "\n",
       "       tBodyAcc-mad()-Y  tBodyAcc-mad()-Z  tBodyAcc-max()-X  ...  \\\n",
       "6505          -0.959690         -0.944281         -0.926421  ...   \n",
       "4384          -0.979116         -0.988149         -0.942968  ...   \n",
       "7480          -0.041149          0.186226          0.315973  ...   \n",
       "5960          -0.987864         -0.990653         -0.930099  ...   \n",
       "10196         -0.982565         -0.980663         -0.916381  ...   \n",
       "\n",
       "       fBodyBodyGyroJerkMag-kurtosis()  angle(tBodyAccMean,gravity)  \\\n",
       "6505                         -0.604272                    -0.135149   \n",
       "4384                         -0.919445                    -0.089110   \n",
       "7480                         -0.639589                     0.368217   \n",
       "5960                         -0.950759                     0.332895   \n",
       "10196                        -0.940910                    -0.090369   \n",
       "\n",
       "       angle(tBodyAccJerkMean),gravityMean)  angle(tBodyGyroMean,gravityMean)  \\\n",
       "6505                              -0.006428                         -0.840651   \n",
       "4384                              -0.044198                         -0.607149   \n",
       "7480                               0.310372                          0.969768   \n",
       "5960                               0.404353                          0.222148   \n",
       "10196                              0.008545                          0.387679   \n",
       "\n",
       "       angle(tBodyGyroJerkMean,gravityMean)  angle(X,gravityMean)  \\\n",
       "6505                               0.548457             -0.690776   \n",
       "4384                               0.601884             -0.817034   \n",
       "7480                              -0.504041             -0.496266   \n",
       "5960                               0.056738              0.604472   \n",
       "10196                             -0.204587              0.449349   \n",
       "\n",
       "       angle(Y,gravityMean)  angle(Z,gravityMean)  subject            Activity  \n",
       "6505               0.291574              0.110070       28             SITTING  \n",
       "4384               0.214795             -0.032885       22            STANDING  \n",
       "7480               0.268661              0.327231        2  WALKING_DOWNSTAIRS  \n",
       "5960              -0.363929             -0.648498       27              LAYING  \n",
       "10196             -0.501789             -0.490746       24              LAYING  \n",
       "\n",
       "[5 rows x 563 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_set = train_set[['Activity']].values.ravel()\n",
    "x_train_set = train_set.drop(['Activity','subject'], axis=1).values\n",
    "\n",
    "x_dev_set = dev_set.drop(['Activity','subject'], axis=1).values\n",
    "y_dev_set = dev_set[['Activity']].values.ravel()\n",
    "\n",
    "x_test_set = test_set.drop(['Activity','subject'], axis=1).values\n",
    "y_test_set = test_set[['Activity']].values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature selection has the purpose to retain from the data only those features that are the most relevant, i.e. useful, purging the data from those which add few or no significant improvement.\n",
    "\n",
    "Dimensionality reduction is different from feature selection, cause it projects the data in a new space, giving as a result a set of new features, whereas feature selection filters out the original features.\n",
    "\n",
    "Feature selection is carried out by statical analyses, such as correlation analysis. For classification tasks on numerical data the ANOVA statistical model is known to be quite good. Then, we leverage its implementation in sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = SelectKBest(score_func=f_classif, k=561)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_set = train_set[['Activity']].values.ravel()\n",
    "x_train_set = fs.fit_transform(train_set.drop(['Activity','subject'], axis=1).values, y_train_set)\n",
    "\n",
    "x_dev_set = fs.transform(dev_set.drop(['Activity','subject'], axis=1))\n",
    "y_dev_set = dev_set[['Activity']].values.ravel()\n",
    "\n",
    "x_test_set = fs.transform(test_set.drop(['Activity','subject'], axis=1))\n",
    "y_test_set = test_set[['Activity']].values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we separate the numeric values from the class labels, dropping the user ID which is useless in our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=310)\n",
    "x_train_set = svd.fit_transform(x_train_set)\n",
    "x_dev_set = svd.transform(x_dev_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.94392155097991"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(svd.explained_variance_ratio_) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Encoding Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encodes the activity labels to numerical labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_train_set = le.fit_transform(y_train_set)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_dev_set = le.fit_transform(y_dev_set)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_test_set = le.fit_transform(y_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the actual corresponding classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LAYING': 0, 'SITTING': 1, 'STANDING': 2, 'WALKING': 3, 'WALKING_DOWNSTAIRS': 4, 'WALKING_UPSTAIRS': 5}\n"
     ]
    }
   ],
   "source": [
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(le_name_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100.0, gamma=0.1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svclassifier = SVC(kernel='rbf', C=100.0, gamma=0.1)\n",
    "svclassifier.fit(x_train_set, y_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svclassifier.predict(x_dev_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[386   0   0   0   5   0]\n",
      " [  0 337   9   0   2   0]\n",
      " [  0   6 359   0   0   0]\n",
      " [  0   0   0 366   1   0]\n",
      " [  0   0   0   1 288   0]\n",
      " [  0   0   0   1   1 298]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       391\n",
      "           1       0.98      0.97      0.98       348\n",
      "           2       0.98      0.98      0.98       365\n",
      "           3       0.99      1.00      1.00       367\n",
      "           4       0.97      1.00      0.98       289\n",
      "           5       1.00      0.99      1.00       300\n",
      "\n",
      "    accuracy                           0.99      2060\n",
      "   macro avg       0.99      0.99      0.99      2060\n",
      "weighted avg       0.99      0.99      0.99      2060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_dev_set,y_pred))\n",
    "print(classification_report(y_dev_set,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_set = svd.transform(x_test_set)\n",
    "y_pred = svclassifier.predict(x_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[394   0   0   0   5   0]\n",
      " [  0 352   7   0   1   0]\n",
      " [  0   8 370   0   3   0]\n",
      " [  0   0   0 324   1   0]\n",
      " [  0   0   0   0 268   0]\n",
      " [  0   0   0   0   2 325]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       399\n",
      "           1       0.98      0.98      0.98       360\n",
      "           2       0.98      0.97      0.98       381\n",
      "           3       1.00      1.00      1.00       325\n",
      "           4       0.96      1.00      0.98       268\n",
      "           5       1.00      0.99      1.00       327\n",
      "\n",
      "    accuracy                           0.99      2060\n",
      "   macro avg       0.99      0.99      0.99      2060\n",
      "weighted avg       0.99      0.99      0.99      2060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test_set,y_pred))\n",
    "print(classification_report(y_test_set,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def select_features(train_set, dev_set, n_features):\n",
    "    fs = SelectKBest(score_func=f_classif, k=n_features)\n",
    "    \n",
    "    x_train_set = fs.fit_transform(train_set.drop(['Activity','subject'], axis=1).values, y_train_set)\n",
    "\n",
    "    x_dev_set = fs.transform(dev_set.drop(['Activity','subject'], axis=1))\n",
    "    \n",
    "    return x_train_set, x_dev_set\n",
    "\n",
    "\n",
    "def reduce_features(x_train_set, x_dev_set, n_components):\n",
    "    svd = TruncatedSVD(n_components=n_components)\n",
    "    \n",
    "    x_train_set = svd.fit_transform(x_train_set)\n",
    "    \n",
    "    x_dev_set = svd.transform(x_dev_set)\n",
    "    \n",
    "    return np.vstack((x_train_set, x_dev_set))\n",
    "\n",
    "\n",
    "def tune_model(train_set, dev_set, estimator, params):\n",
    "    log_result = {}\n",
    "    test_fold = np.append(np.full((train_set.shape[0],), -1, dtype=int), np.full((dev_set.shape[0],), 0, dtype=int))\n",
    "    ps = PredefinedSplit(test_fold)\n",
    "    y_train_dev = np.vstack((train_set[['Activity']].values, dev_set[['Activity']].values)).ravel()\n",
    "    for n_features in tqdm((50, 100, 300, 400, 561)):\n",
    "        log_result[n_features] = {}\n",
    "        x_train_set, x_dev_set = select_features(train_set, dev_set, n_features)\n",
    "        for n_components in range(10, n_features, 50):\n",
    "            train_dev_set = reduce_features(x_train_set, x_dev_set, n_components)\n",
    "            grid = GridSearchCV(estimator=estimator, param_grid=params, scoring='accuracy', cv=ps)\n",
    "            grid.fit(train_dev_set, y_train_dev)\n",
    "            log_result[n_features][n_components] = (grid.best_score_, grid.best_params_)\n",
    "    return log_result\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [25:36<00:00, 307.27s/it]\n"
     ]
    }
   ],
   "source": [
    "params={'kernel':['linear','rbf'],'C':[1,10,100],'gamma':[1e-2,1e-3,1e-4]}\n",
    "result = tune_model(train_set, dev_set, SVC(), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(561, 360) (0.9912621359223301, {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'})\n"
     ]
    }
   ],
   "source": [
    "max_acc = []\n",
    "index = []\n",
    "for n_features in (50, 100, 300, 400, 561):\n",
    "    for n_components in range(10, n_features, 50):\n",
    "        max_acc.append(result[n_features][n_components][0])\n",
    "        index.append((n_features, n_components))\n",
    "            \n",
    "i = np.argsort(np.array(max_acc))\n",
    "#print(np.array(max_acc)[i[-25:]])\n",
    "#print(np.array(index)[i[-25:]])\n",
    "print(index[i[-5]], result[561][360])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gda(x, y, x_test, y_test):\n",
    "    y_classes, y_counts = np.unique(y, return_counts=True)\n",
    "    p_y = 1.0 * y_counts/len(y)\n",
    "    mu = np.array([ x[y==k].mean(axis=0) for k in y_classes])\n",
    "    sigma = compute_sigma(x, y, mu, y_classes)\n",
    "    #adding noise\n",
    "    sigma += np.ones_like(sigma) * 1e-10\n",
    "    sigma = np.linalg.pinv(sigma)\n",
    "    return predict(x_test, mu, sigma, p_y)\n",
    "\n",
    "def compute_sigma(x, y, mu, y_classes):\n",
    "    x_u = x.copy()\n",
    "    for i in range(len(mu)):\n",
    "        x_u[y==y_classes[i]] -= mu[i]\n",
    "    return x_u.T.dot(x_u) / len(y)\n",
    "    \n",
    "def predict(data, mu, sigma, p_y):\n",
    "    return np.apply_along_axis(lambda x: (np.argmax(np.exp(-0.5 * np.sum((x - mu).dot(sigma) * (x - mu), axis =1)) * p_y)), 1, data)\n",
    "\n",
    "def score(x, y, mu, sigma, p_y):\n",
    "    return (predict(x, mu, sigma, p_y) == y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gda(x_train_set, y_train_set, x_test_set, y_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9393203883495146"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9436893203883495"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gda(x_train_set, y_train_set, x_dev_set, y_dev_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       399\n",
      "           1       0.93      0.94      0.93       360\n",
      "           2       0.94      0.94      0.94       381\n",
      "           3       0.99      0.99      0.99       325\n",
      "           4       0.99      0.96      0.97       268\n",
      "           5       0.98      0.99      0.98       327\n",
      "\n",
      "    accuracy                           0.97      2060\n",
      "   macro avg       0.97      0.97      0.97      2060\n",
      "weighted avg       0.97      0.97      0.97      2060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fs = SelectKBest(score_func=f_classif, k=561)\n",
    "svd = TruncatedSVD(n_components=260)\n",
    "        \n",
    "x_train_set_r = svd.fit_transform(fs.fit_transform(train_set.drop(['Activity','subject'], axis=1).values, y_train_set))\n",
    "\n",
    "x_dev_set_r = svd.transform(fs.transform(dev_set.drop(['Activity','subject'], axis=1)))\n",
    "\n",
    "x_test_set_r = svd.transform(fs.transform(test_set.drop(['Activity','subject'], axis=1)))\n",
    "\n",
    "y_pred = gda(x_train_set_r, y_train_set, x_test_set_r, y_test_set)\n",
    "print(classification_report(y_test_set,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "for n_features in (50, 100, 300, 400, 561):\n",
    "    fs = SelectKBest(score_func=f_classif, k=n_features)\n",
    "    result[n_features] = {}\n",
    "    for n_components in range(10, n_features, 50):\n",
    "        svd = TruncatedSVD(n_components=n_components)\n",
    "        \n",
    "        x_train_set_r = svd.fit_transform(fs.fit_transform(train_set.drop(['Activity','subject'], axis=1).values, y_train_set))\n",
    "\n",
    "        x_dev_set_r = svd.transform(fs.transform(dev_set.drop(['Activity','subject'], axis=1)))\n",
    "\n",
    "        x_test_set_r = svd.transform(fs.transform(test_set.drop(['Activity','subject'], axis=1)))\n",
    "        result[n_features][n_components] = gda(x_train_set_r, y_train_set, x_test_set_r, y_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(561, 260) 0.9684466019417476\n"
     ]
    }
   ],
   "source": [
    "max_acc = []\n",
    "index = []\n",
    "for n_features in (50, 100, 300, 400, 561):\n",
    "    for n_components in range(10, n_features, 50):\n",
    "        max_acc.append(result[n_features][n_components])\n",
    "        index.append((n_features, n_components))\n",
    "        \n",
    "i = np.argsort(np.array(max_acc))\n",
    "#print(np.array(max_acc)[i[-20:]])\n",
    "#print(np.array(index)[i[-20:]])\n",
    "print(index[i[-1]], result[561][260])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9548543689320388"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values[56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9504854368932039"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gda(x_train_set_r, y_train_set, x_test_set_r, y_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_features_gda(x_train, x_dev, n_components):\n",
    "    svd = TruncatedSVD(n_components=n_components)\n",
    "    \n",
    "    x_train = svd.fit_transform(x_train)\n",
    "    \n",
    "    x_dev = svd.transform(x_dev)\n",
    "    \n",
    "    return x_train_set, x_dev_set\n",
    "\n",
    "\n",
    "\n",
    "def tune_model_gda(train_set, dev_set, estimator, params):\n",
    "    log_result = {}\n",
    "    test_fold = np.append(np.full((train_set.shape[0],), -1, dtype=int), np.full((dev_set.shape[0],), 0, dtype=int))\n",
    "    ps = PredefinedSplit(test_fold)\n",
    "    y_train_dev = np.vstack((train_set[['Activity']].values, dev_set[['Activity']].values)).ravel()\n",
    "    for n_features in tqdm((50, 100, 300, 400, 561)):\n",
    "        log_result[n_features] = {}\n",
    "        for n_components in range(10, n_features, 50):\n",
    "            x_train_set_r, x_dev_set_r = select_features(train_set, dev_set, n_features)\n",
    "            x_train_set_r, x_dev_set_r = reduce_features_gda(x_train_set_r, x_dev_set_r, n_components)\n",
    "            log_result[n_features][n_components] = gda(x_train_set_r, train_set[['Activity']].values.ravel(), x_dev_set_r, dev_set[['Activity']].values.ravel())\n",
    "    return log_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:36<00:00,  7.23s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{50: {10: 0.0},\n",
       " 100: {10: 0.0, 60: 0.0},\n",
       " 300: {10: 0.0, 60: 0.0, 110: 0.0, 160: 0.0, 210: 0.0, 260: 0.0},\n",
       " 400: {10: 0.0,\n",
       "  60: 0.0,\n",
       "  110: 0.0,\n",
       "  160: 0.0,\n",
       "  210: 0.0,\n",
       "  260: 0.0,\n",
       "  310: 0.0,\n",
       "  360: 0.0},\n",
       " 561: {10: 0.0,\n",
       "  60: 0.0,\n",
       "  110: 0.0,\n",
       "  160: 0.0,\n",
       "  210: 0.0,\n",
       "  260: 0.0,\n",
       "  310: 0.0,\n",
       "  360: 0.0,\n",
       "  410: 0.0,\n",
       "  460: 0.0,\n",
       "  510: 0.0,\n",
       "  560: 0.0}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune_model_gda(train_set, dev_set, gda, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
