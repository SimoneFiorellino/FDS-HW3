{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Train/Dev/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has been already splitted into train and test sets, with a ratio of about 70/30%. \n",
    "\n",
    "For our classification task, in order to fine tune the hyperparameters of the model and select the best features from the data, we further split those sets. So, we end up with train, evaluation and test sets of about 60/20/20% of the overall data, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./data/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take 2/5 of the train set for cross validation and test\n",
    "train_set, dev_test_set = train_test_split(dataset, test_size=0.4, random_state=12)\n",
    "\n",
    "# take 1/2 of the test set for cross validation\n",
    "test_set, dev_set = train_test_split(dev_test_set, test_size=0.5, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tBodyAcc-mean()-X</th>\n",
       "      <th>tBodyAcc-mean()-Y</th>\n",
       "      <th>tBodyAcc-mean()-Z</th>\n",
       "      <th>tBodyAcc-std()-X</th>\n",
       "      <th>tBodyAcc-std()-Y</th>\n",
       "      <th>tBodyAcc-std()-Z</th>\n",
       "      <th>tBodyAcc-mad()-X</th>\n",
       "      <th>tBodyAcc-mad()-Y</th>\n",
       "      <th>tBodyAcc-mad()-Z</th>\n",
       "      <th>tBodyAcc-max()-X</th>\n",
       "      <th>...</th>\n",
       "      <th>fBodyBodyGyroJerkMag-kurtosis()</th>\n",
       "      <th>angle(tBodyAccMean,gravity)</th>\n",
       "      <th>angle(tBodyAccJerkMean),gravityMean)</th>\n",
       "      <th>angle(tBodyGyroMean,gravityMean)</th>\n",
       "      <th>angle(tBodyGyroJerkMean,gravityMean)</th>\n",
       "      <th>angle(X,gravityMean)</th>\n",
       "      <th>angle(Y,gravityMean)</th>\n",
       "      <th>angle(Z,gravityMean)</th>\n",
       "      <th>subject</th>\n",
       "      <th>Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6505</th>\n",
       "      <td>0.278909</td>\n",
       "      <td>-0.016122</td>\n",
       "      <td>-0.108804</td>\n",
       "      <td>-0.991421</td>\n",
       "      <td>-0.958884</td>\n",
       "      <td>-0.943642</td>\n",
       "      <td>-0.992854</td>\n",
       "      <td>-0.959690</td>\n",
       "      <td>-0.944281</td>\n",
       "      <td>-0.926421</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.604272</td>\n",
       "      <td>-0.135149</td>\n",
       "      <td>-0.006428</td>\n",
       "      <td>-0.840651</td>\n",
       "      <td>0.548457</td>\n",
       "      <td>-0.690776</td>\n",
       "      <td>0.291574</td>\n",
       "      <td>0.110070</td>\n",
       "      <td>28</td>\n",
       "      <td>SITTING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4384</th>\n",
       "      <td>0.278544</td>\n",
       "      <td>-0.017497</td>\n",
       "      <td>-0.111402</td>\n",
       "      <td>-0.997560</td>\n",
       "      <td>-0.980832</td>\n",
       "      <td>-0.987017</td>\n",
       "      <td>-0.997578</td>\n",
       "      <td>-0.979116</td>\n",
       "      <td>-0.988149</td>\n",
       "      <td>-0.942968</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.919445</td>\n",
       "      <td>-0.089110</td>\n",
       "      <td>-0.044198</td>\n",
       "      <td>-0.607149</td>\n",
       "      <td>0.601884</td>\n",
       "      <td>-0.817034</td>\n",
       "      <td>0.214795</td>\n",
       "      <td>-0.032885</td>\n",
       "      <td>22</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7480</th>\n",
       "      <td>0.243931</td>\n",
       "      <td>-0.004004</td>\n",
       "      <td>-0.122676</td>\n",
       "      <td>-0.092084</td>\n",
       "      <td>0.010789</td>\n",
       "      <td>0.199388</td>\n",
       "      <td>-0.193510</td>\n",
       "      <td>-0.041149</td>\n",
       "      <td>0.186226</td>\n",
       "      <td>0.315973</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.639589</td>\n",
       "      <td>0.368217</td>\n",
       "      <td>0.310372</td>\n",
       "      <td>0.969768</td>\n",
       "      <td>-0.504041</td>\n",
       "      <td>-0.496266</td>\n",
       "      <td>0.268661</td>\n",
       "      <td>0.327231</td>\n",
       "      <td>2</td>\n",
       "      <td>WALKING_DOWNSTAIRS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5960</th>\n",
       "      <td>0.278354</td>\n",
       "      <td>-0.016345</td>\n",
       "      <td>-0.111278</td>\n",
       "      <td>-0.985230</td>\n",
       "      <td>-0.988805</td>\n",
       "      <td>-0.990760</td>\n",
       "      <td>-0.985383</td>\n",
       "      <td>-0.987864</td>\n",
       "      <td>-0.990653</td>\n",
       "      <td>-0.930099</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.950759</td>\n",
       "      <td>0.332895</td>\n",
       "      <td>0.404353</td>\n",
       "      <td>0.222148</td>\n",
       "      <td>0.056738</td>\n",
       "      <td>0.604472</td>\n",
       "      <td>-0.363929</td>\n",
       "      <td>-0.648498</td>\n",
       "      <td>27</td>\n",
       "      <td>LAYING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10196</th>\n",
       "      <td>0.291115</td>\n",
       "      <td>-0.014618</td>\n",
       "      <td>-0.112456</td>\n",
       "      <td>-0.968179</td>\n",
       "      <td>-0.982618</td>\n",
       "      <td>-0.983055</td>\n",
       "      <td>-0.967095</td>\n",
       "      <td>-0.982565</td>\n",
       "      <td>-0.980663</td>\n",
       "      <td>-0.916381</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.940910</td>\n",
       "      <td>-0.090369</td>\n",
       "      <td>0.008545</td>\n",
       "      <td>0.387679</td>\n",
       "      <td>-0.204587</td>\n",
       "      <td>0.449349</td>\n",
       "      <td>-0.501789</td>\n",
       "      <td>-0.490746</td>\n",
       "      <td>24</td>\n",
       "      <td>LAYING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 563 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tBodyAcc-mean()-X  tBodyAcc-mean()-Y  tBodyAcc-mean()-Z  \\\n",
       "6505            0.278909          -0.016122          -0.108804   \n",
       "4384            0.278544          -0.017497          -0.111402   \n",
       "7480            0.243931          -0.004004          -0.122676   \n",
       "5960            0.278354          -0.016345          -0.111278   \n",
       "10196           0.291115          -0.014618          -0.112456   \n",
       "\n",
       "       tBodyAcc-std()-X  tBodyAcc-std()-Y  tBodyAcc-std()-Z  tBodyAcc-mad()-X  \\\n",
       "6505          -0.991421         -0.958884         -0.943642         -0.992854   \n",
       "4384          -0.997560         -0.980832         -0.987017         -0.997578   \n",
       "7480          -0.092084          0.010789          0.199388         -0.193510   \n",
       "5960          -0.985230         -0.988805         -0.990760         -0.985383   \n",
       "10196         -0.968179         -0.982618         -0.983055         -0.967095   \n",
       "\n",
       "       tBodyAcc-mad()-Y  tBodyAcc-mad()-Z  tBodyAcc-max()-X  ...  \\\n",
       "6505          -0.959690         -0.944281         -0.926421  ...   \n",
       "4384          -0.979116         -0.988149         -0.942968  ...   \n",
       "7480          -0.041149          0.186226          0.315973  ...   \n",
       "5960          -0.987864         -0.990653         -0.930099  ...   \n",
       "10196         -0.982565         -0.980663         -0.916381  ...   \n",
       "\n",
       "       fBodyBodyGyroJerkMag-kurtosis()  angle(tBodyAccMean,gravity)  \\\n",
       "6505                         -0.604272                    -0.135149   \n",
       "4384                         -0.919445                    -0.089110   \n",
       "7480                         -0.639589                     0.368217   \n",
       "5960                         -0.950759                     0.332895   \n",
       "10196                        -0.940910                    -0.090369   \n",
       "\n",
       "       angle(tBodyAccJerkMean),gravityMean)  angle(tBodyGyroMean,gravityMean)  \\\n",
       "6505                              -0.006428                         -0.840651   \n",
       "4384                              -0.044198                         -0.607149   \n",
       "7480                               0.310372                          0.969768   \n",
       "5960                               0.404353                          0.222148   \n",
       "10196                              0.008545                          0.387679   \n",
       "\n",
       "       angle(tBodyGyroJerkMean,gravityMean)  angle(X,gravityMean)  \\\n",
       "6505                               0.548457             -0.690776   \n",
       "4384                               0.601884             -0.817034   \n",
       "7480                              -0.504041             -0.496266   \n",
       "5960                               0.056738              0.604472   \n",
       "10196                             -0.204587              0.449349   \n",
       "\n",
       "       angle(Y,gravityMean)  angle(Z,gravityMean)  subject            Activity  \n",
       "6505               0.291574              0.110070       28             SITTING  \n",
       "4384               0.214795             -0.032885       22            STANDING  \n",
       "7480               0.268661              0.327231        2  WALKING_DOWNSTAIRS  \n",
       "5960              -0.363929             -0.648498       27              LAYING  \n",
       "10196             -0.501789             -0.490746       24              LAYING  \n",
       "\n",
       "[5 rows x 563 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature selection has the purpose to retain from the data only those features that are the most relevant, i.e. useful, purging the data from those which add few or no significant improvement.\n",
    "\n",
    "Dimensionality reduction is different from feature selection, cause it projects the data in a new space, giving as a result a set of new features, whereas feature selection filters out the original features.\n",
    "\n",
    "Feature selection is carried out by statical analyses, such as correlation analysis. For classification tasks on numerical data the ANOVA statistical model is known to be quite good. Then, we leverage its implementation in sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = SelectKBest(score_func=f_classif, k=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_set = train_set[['Activity']].values.ravel()\n",
    "x_train_set = fs.fit_transform(train_set.drop(['Activity','subject'], axis=1).values, y_train_set)\n",
    "\n",
    "x_dev_set = fs.transform(dev_set.drop(['Activity','subject'], axis=1))\n",
    "y_dev_set = dev_set[['Activity']].values.ravel()\n",
    "\n",
    "x_test_set = fs.transform(test_set.drop(['Activity','subject'], axis=1))\n",
    "y_test_set = test_set[['Activity']].values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we separate the numeric values from the class labels, dropping the user ID which is useless in our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=200)\n",
    "x_train_set = svd.fit_transform(x_train_set)\n",
    "x_dev_set = svd.transform(x_dev_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.93919674583786"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(svd.explained_variance_ratio_) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Encoding Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encodes the activity labels to numerical labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_train_set = le.fit_transform(y_train_set)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_dev_set = le.fit_transform(y_dev_set)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_test_set = le.fit_transform(y_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the actual corresponding classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LAYING': 0, 'SITTING': 1, 'STANDING': 2, 'WALKING': 3, 'WALKING_DOWNSTAIRS': 4, 'WALKING_UPSTAIRS': 5}\n"
     ]
    }
   ],
   "source": [
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(le_name_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svclassifier = SVC(kernel='rbf', C=100.0)\n",
    "svclassifier.fit(x_train_set, y_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svclassifier.predict(x_dev_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[391   0   0   0   0   0]\n",
      " [  0 331  17   0   0   0]\n",
      " [  0  12 353   0   0   0]\n",
      " [  0   0   0 367   0   0]\n",
      " [  0   0   0   0 289   0]\n",
      " [  0   0   0   0   0 300]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       391\n",
      "           1       0.97      0.95      0.96       348\n",
      "           2       0.95      0.97      0.96       365\n",
      "           3       1.00      1.00      1.00       367\n",
      "           4       1.00      1.00      1.00       289\n",
      "           5       1.00      1.00      1.00       300\n",
      "\n",
      "    accuracy                           0.99      2060\n",
      "   macro avg       0.99      0.99      0.99      2060\n",
      "weighted avg       0.99      0.99      0.99      2060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_dev_set,y_pred))\n",
    "print(classification_report(y_dev_set,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X.shape[1] = 400 should be equal to 200, the number of features at training time",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-1875ca906084>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mndarray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \"\"\"\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    482\u001b[0m                                  (X.shape[1], self.shape_fit_[0]))\n\u001b[1;32m    483\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_fit_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             raise ValueError(\"X.shape[1] = %d should be equal to %d, \"\n\u001b[0m\u001b[1;32m    485\u001b[0m                              \u001b[0;34m\"the number of features at training time\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m                              (X.shape[1], self.shape_fit_[1]))\n",
      "\u001b[0;31mValueError\u001b[0m: X.shape[1] = 400 should be equal to 200, the number of features at training time"
     ]
    }
   ],
   "source": [
    "y_pred = svclassifier.predict(x_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[399   0   0   0   0   0]\n",
      " [  0 288  72   0   0   0]\n",
      " [  0  83 298   0   0   0]\n",
      " [  0   0   0 318   1   6]\n",
      " [  0   0   0   1 262   5]\n",
      " [  0   0   0   8   1 318]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       399\n",
      "           1       0.78      0.80      0.79       360\n",
      "           2       0.81      0.78      0.79       381\n",
      "           3       0.97      0.98      0.98       325\n",
      "           4       0.99      0.98      0.98       268\n",
      "           5       0.97      0.97      0.97       327\n",
      "\n",
      "    accuracy                           0.91      2060\n",
      "   macro avg       0.92      0.92      0.92      2060\n",
      "weighted avg       0.91      0.91      0.91      2060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test_set,y_pred))\n",
    "print(classification_report(y_test_set,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def select_features(train_set, dev_set, n_features):\n",
    "    fs = SelectKBest(score_func=f_classif, k=n_features)\n",
    "    \n",
    "    x_train_set = fs.fit_transform(train_set.drop(['Activity','subject'], axis=1).values, y_train_set)\n",
    "\n",
    "    x_dev_set = fs.transform(dev_set.drop(['Activity','subject'], axis=1))\n",
    "    \n",
    "    return x_train_set, x_dev_set\n",
    "\n",
    "\n",
    "def reduce_features(x_train_set, x_dev_set, n_components):\n",
    "    svd = TruncatedSVD(n_components=n_components)\n",
    "    \n",
    "    x_train_set = svd.fit_transform(x_train_set)\n",
    "    \n",
    "    x_dev_set = svd.transform(x_dev_set)\n",
    "    \n",
    "    return np.vstack((x_train_set, x_dev_set))\n",
    "\n",
    "\n",
    "def tune_model(train_set, dev_set, estimator, params):\n",
    "    log_result = {}\n",
    "    test_fold = np.append(np.full((train_set.shape[0],), -1, dtype=int), np.full((dev_set.shape[0],), 0, dtype=int))\n",
    "    ps = PredefinedSplit(test_fold)\n",
    "    y_train_dev = np.vstack((train_set[['Activity']].values, dev_set[['Activity']].values)).ravel()\n",
    "    for n_features in tqdm((50, 100, 300, 400, 561)):\n",
    "        log_result[n_features] = {}\n",
    "        x_train_set, x_dev_set = select_features(train_set, dev_set, n_features)\n",
    "        for n_components in range(10, n_features, 50):\n",
    "            train_dev_set = reduce_features(x_train_set, x_dev_set, n_components)\n",
    "            grid = GridSearchCV(estimator=estimator, param_grid=params, scoring='accuracy', cv=ps)\n",
    "            grid.fit(train_dev_set, y_train_dev)\n",
    "            log_result[n_features][n_components] = (grid.best_score_, grid.best_params_)\n",
    "    return log_result\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [25:36<00:00, 307.27s/it]\n"
     ]
    }
   ],
   "source": [
    "params={'kernel':['linear','rbf'],'C':[1,10,100],'gamma':[1e-2,1e-3,1e-4]}\n",
    "result = tune_model(train_set, dev_set, SVC(), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(561, 360) (0.9912621359223301, {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'})\n"
     ]
    }
   ],
   "source": [
    "max_acc = []\n",
    "index = []\n",
    "for n_features in (50, 100, 300, 400, 561):\n",
    "    for n_components in range(10, n_features, 50):\n",
    "        max_acc.append(result[n_features][n_components][0])\n",
    "        index.append((n_features, n_components))\n",
    "            \n",
    "i = np.argsort(np.array(max_acc))\n",
    "#print(np.array(max_acc)[i[-25:]])\n",
    "#print(np.array(index)[i[-25:]])\n",
    "print(index[i[-5]], result[561][360])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GDA Multi-Classification OVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the phi y parameter, now we are inserting the methods that estimate the parameters for the GDA analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_phi(y):\n",
    "    return np.mean(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the mean for the first vector and second vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mu0(x, y):\n",
    "    indicator_f = 1-y.reshape(y.shape[0], 1)\n",
    "\n",
    "    sum_x = 0\n",
    "    for i in range(0, x.shape[0]):\n",
    "        sum_x +=indicator_f[i] * x[i]\n",
    "    \n",
    "    return sum_x / np.sum(indicator_f)\n",
    "\n",
    "\n",
    "def compute_mu1(x, y):\n",
    "    indicator_f = y.reshape(y.shape[0], 1)\n",
    "    \n",
    "    sum_x = 0\n",
    "    for i in range(0, x.shape[0]):\n",
    "        sum_x += indicator_f[i] * x[i]\n",
    "    \n",
    "    return sum_x / np.sum(indicator_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sigma(x, y, mu0, mu1):\n",
    "    my_sum = 0\n",
    "    for i in range(0, x.shape[0]):\n",
    "        if y[i]==0:\n",
    "            my_sum+=(x[i] - mu0).reshape(x.shape[1], 1) @ (x[i] - mu0).reshape(x.shape[1], 1).T\n",
    "        else:\n",
    "            my_sum+=(x[i] - mu1).reshape(x.shape[1], 1) @ (x[i] - mu1).reshape(x.shape[1], 1).T\n",
    "            \n",
    "    return (1 / x.shape[0]) * (my_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the probability of x give y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing p(x|y) for the Bayes rule\n",
    "def p_x_given_y(x,mu,sigma):  \n",
    "    d = x.shape[0]\n",
    "    return (1 / (((2*np.pi)**(d/2)) * (np.linalg.det(sigma)**0.5))) * np.exp(-0.5*(x - mu) @ np.linalg.inv(sigma) @ (x - mu))\n",
    "\n",
    "# Function p(y) for applying the Bayes rule\n",
    "def p_y(y,phi):\n",
    "    if abs(y)==1: return phi\n",
    "    else: return 1 - phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected example = [0.928801   0.85808986 0.94499787 0.80917682 0.65810016 0.72029408\n",
      " 0.55315077 0.53497811 0.62244386 0.38211905] \n",
      "\n",
      "p(y=0|x) ~ 1.9866046722794367e-28\n",
      "p(y=1|x) ~ 893783.7291330532\n",
      "p(y=1|x) ~ 1814.5070550259309\n",
      "p(y=1|x) ~ 231886.4838062258\n",
      "p(y=2|x) ~ 1626.5160686718027\n",
      "p(y=1|x) ~ 247106.33405376732\n",
      "p(y=3|x) ~ 134223.67329465155\n",
      "p(y=1|x) ~ 53830.9856840042\n",
      "p(y=4|x) ~ 5350.579906360915\n",
      "p(y=1|x) ~ 183700.30797465434\n",
      "p(y=5|x) ~ 40582.90941693707\n",
      "p(y=1|x) ~ 137513.41795511777\n"
     ]
    }
   ],
   "source": [
    "# Now estimate the GDA parameters and start for one vs all\n",
    "selected_example=1\n",
    "print('Selected example =', x_test_set[selected_example,:], \"\\n\")\n",
    "\n",
    "for label in [0, 1, 2, 3, 4, 5]:\n",
    "    y = y_train_set.copy()\n",
    "    y = np.where(y != label, -1, y) # the rest is set to -1\n",
    "    y = np.where(y == label, 0, y) # the value point that we want to compare with the rest is set to zero\n",
    "    y = abs(y)\n",
    "    \n",
    "    phi = compute_phi(y)\n",
    "    mu0 = compute_mu0(x_train_set, y)\n",
    "    mu1 = compute_mu1(x_train_set, y)\n",
    "    sigma = compute_sigma(x_train_set, y, mu0, mu1)\n",
    "\n",
    "    # compute p(y=l|x) ~ p(x|y=0)*p(y=0)  &  p(y=1|x) ~ p(x|y=1)*p(y=1) where l is one class\n",
    "\n",
    "    # y=0\n",
    "    print('p(y=' + str(label) + '|x) ~', p_x_given_y(x_test_set[selected_example,:],mu0,sigma)*p_y(0, phi))\n",
    "\n",
    "    # y=1\n",
    "    print('p(y=1|x) ~', p_x_given_y(x_test_set[selected_example,:],mu1,sigma)*p_y(1, phi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
