\documentclass[a4paper,10pt,oneside]{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{hyperref}


\hypersetup {
        colorlinks=true,
        linkcolor=blue,
        anchorcolor=black,
        filecolor=magenta,
        urlcolor=cyan,
        citecolor=blue
}

%opening
\title{Human Activity Recognition With Smartphones}
\author{Jeremy Sapienza, Simone Fiorellino, Stefano D'Arrigo}

\begin{document}

\maketitle

\begin{abstract}
 
\end{abstract}


%sds

\section{Introduction}
Nowadays everyone has a smartphone in his pocket and carries it everywhere he goes during the day journey. Smartphones collect each time a huge amount of data through their embedded sensors. High tech industries are involved into the development of accurate wearable devices to improve every day life, monitoring the activities of their customers, from walking in a park to laying on the bed.\\
%Hence, it would be valuable to leverage the information coming from mobile devices to recognize human activities. Useless to say, high classification performance is strongly required.
Hence, we reckoned this topic valuable and in our project we focused on the classification task of human activities, making use of accelerometer and gyroscope records. Our attention was particularly concentrated on the training of two classifiers, GDA and SVM,  and on the research of a convenient data representation.
In this report we summarize the methods we applied and the choices we made. Finally, in the last section we present our findings and give some further analyses.


\section{Related work}
For this work we were inspired by the paper \cite{brown2013activity}.
The research focuses on developing a classifier that operates on accelerometer and gyroscope data from mobile phones.
As explained in \cite{anuita2013human}, they recorded the stream of data of 30 subjects during different types of activity: walking, walking up stairs, walking down stairs, sitting, standing and laying.

The dataset have two types of data:
\begin{itemize}
 \item “Raw data”: raw gyroscope and accelerometer readings.
 \item “Preprocessed data”: Vectors of  561 features that represent 2.56s of time. These features represent different functions, some examples are: triaxial average, maximum and minimum acceleration, angular velocity (over the given interval) or Fourier transform.
\end{itemize}

They used for this part of work the preprocessed data.

To approach this problem they used three difference models:
\begin{itemize}
 \item Naives Bayes
 \item GDA
 \item GDA + Hidden Markov Model
\end{itemize}

The GDA accuracy is much higher than the Naive Bayes model because this last model makes the assumption that the features are independent of each other. But, in this context, having the features more correlated together, the accuracy with the Naive Bayes model is pretty low.

Another important aspect of this paper is the dimensionality reduction. They used the PCA in order to decrease the computational complexity of the model and improve the accuracy.


\section{Methods}

\subsection{Data preprocessing}
We retained 60\% of the data for the models' training; the remaining part was equally splitted into evaluation and test sets.
 
\subsection{Models}
As a first step, we implemented the Gaussian Discriminant Analysis classifier and trained it on the data; the choice of this model was mainly conditioned by \cite{brown2013activity}. For the implementation, we faced out with the problem of multiclass classification, as in \cite{guillame2020}. With the purpose of improving the performance, we took into account a step of feature selection and dimensionality reduction: indeed, the high number of derived features forced us to focus on the relationship between the features of the original dataset, the variance of them and the predicted classes. So, we considered two different strategies:
\begin{itemize}
 \item feature selection with the Analysis of Variance (ANOVA) model;
 \item dimensionality reduction with the Singular Value Decomposition (SVD) method.
\end{itemize}
The second step was training the Support Vector Machine classifier on the data, following the same approach just described. After reviewing \cite{james2013introduction, aggarwal2015data, ma_ng_re_2009} and having tried to implement it as in \cite{platt1998sequential, kowalczyk2017support}, we decided to use the implementation given by the library “Scikit Learn” \cite{scikit-learn, sklearn_api}. In this case, it was essential finding a good configuration of feature space and model hyper-parameters. Since this research would have taken too much to be conducted on each possible combination of hyper-parameters, we chose a set of them which we reckoned reasonable.\\ The results of the training and fine tuning step will be presented and commented on in the next section.

\section{Experimental results}

\section{Conclusion and future work}

\bibliography{references}
\bibliographystyle{abbrv}

\end{document}
